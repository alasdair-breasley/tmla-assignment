{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Alasdair Breasley\"\n",
    "CIS_USERNAME = \"fmcv76\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2ed8244d1822167b9619a27c5056a2d",
     "grade": false,
     "grade_id": "cell-c772e32fbd55cccd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# COMP42415 Text Mining and Language Analytics\n",
    "## Coursework 2023-24\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "- <ins>**DO NOT RENAME THIS JUPYTER NOTEBOOK !!!**</ins>\n",
    "- Please write the answers for each question in the respective cell. \n",
    "- You can add more cells if needed.\n",
    "- If needed, you can upload additional files, e.g. pre-trained word embeddings, in the coursework's directory\n",
    "- You can safely remove the `raise NotImplementedError()` line from each code cell.\n",
    "- You can find information about markdown syntax from [here](https://www.markdownguide.org/basic-syntax/#emphasis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "from nltk import pos_tag\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score,precision_score, recall_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set() # Use seaborn plotting style\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import ast\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls \n",
    "load_preprocessed_data = True\n",
    "load_precalculated_w2v_embeddings_300 = True\n",
    "load_precalculated_w2v_docs_vectorised = True\n",
    "load_precalculated_w2v_embeddings_50 = True\n",
    "load_precalculated_w2v_words_vectorised = True\n",
    "\n",
    "load_NB = True\n",
    "run_kNN = False\n",
    "run_kNN_cross_validation = False\n",
    "load_kNN = True\n",
    "load_CNN = True\n",
    "load_LSTM = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "068e2a188a6a3db5c142be9d8afbb053",
     "grade": false,
     "grade_id": "cell-7f0204ddaabf431f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 1\n",
    "Prepare the dataset by applying any pre-processing or cleaning steps that you consider as necessary. Then, split the dataset into a training set containing 70% of the samples and a test set containing 30% of the samples. Follow an appropriate strategy for the split. You must use these training/test sets for all the models in this coursework. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d8184a650c6efb613adc101bb08baf9",
     "grade": true,
     "grade_id": "cell-1ec6ac90f0506a35",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    # Import food reviews data \n",
    "    food_reviews_data = pd.read_csv(\"food_reviews.csv\")\n",
    "    \n",
    "    # Check dataframe head \n",
    "    print(food_reviews_data.head(5), \"\\n\")\n",
    "    \n",
    "    # Check dataframe shape \n",
    "    print(food_reviews_data.shape, \"\\n\")\n",
    "    \n",
    "    # Check data types \n",
    "    print(food_reviews_data.dtypes, \"\\n\")\n",
    "    \n",
    "    # Check for missing values \n",
    "    print(food_reviews_data.isna().sum())\n",
    "    \n",
    "    # Check uniqueness of Score column \n",
    "    print(food_reviews_data[\"Score\"].unique(), \"\\n\")\n",
    "    \n",
    "    # Check for duplicate rows \n",
    "    print(food_reviews_data[food_reviews_data.duplicated()].shape[0], \"\\n\")\n",
    "    \n",
    "    # Remove duplicate rows \n",
    "    food_reviews_data = food_reviews_data.drop_duplicates()\n",
    "    \n",
    "    # Recheck dataframe shape \n",
    "    print(food_reviews_data.shape, \"\\n\")\n",
    "    \n",
    "    # Concatenate Summary column with Text column to capture all available information \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Summary\"].astype(str) + \" \" + food_reviews_data[\"Text\"].astype(str)\n",
    "    \n",
    "    # Check how many rows contain html tags \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"<.+?>\").sum(), \"\\n\")\n",
    "    \n",
    "    # Replace html tags with \" \", \" \" as opposed to \"\" to not join words unintentionally \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"<.+?>\", \" \", regex = True)\n",
    "    \n",
    "    # Recheck how many rows contain html tags \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"<.+?>\").sum(), \"\\n\")\n",
    "    \n",
    "    # Transform Text column to all lowercase \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.lower()\n",
    "    \n",
    "    # Remove all \"-\", \".\", \"'\" and replace with \"\" e.g. lower-case to lowercase, U.K to UK, don't to dont \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[-.']\", \"\", regex = True)\n",
    "    \n",
    "    # Check how many rows include happy or sad text emojis \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[:][)]|[:][(]|[)][:]|[(][:]\").sum(), \"\\n\")\n",
    "    \n",
    "    # Replace happy emojis with \" happy \" \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[:][)]|[(][:]\", \" happy \", regex = True)\n",
    "    \n",
    "    # Replace sad emojis with \" sad \" \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[:][(]|[)][:]\", \" sad \", regex = True)\n",
    "    \n",
    "    # Recheck how many rows include happy or sad text emojis \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[:][)]|[:][(]|[)][:]|[(][:]\").sum(), \"\\n\")\n",
    "    \n",
    "    # Check how many rows include punctuation \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[^\\w\\s]\").sum(), \"\\n\")\n",
    "\n",
    "    # Remove punctuation \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[^\\w\\s]\", \" \", regex = True)\n",
    "    \n",
    "    # Recheck how many rows include punctuation \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[^\\w\\s]\").sum(), \"\\n\")\n",
    "    \n",
    "    # Check for class imbalance \n",
    "    print(food_reviews_data[\"Score\"].value_counts(), \"\\n\")\n",
    "    \n",
    "    # There is class imbalance present \n",
    "    \n",
    "    # Check dataframe head \n",
    "    print(food_reviews_data.head(5), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wordnet(penn_pos_tag):\n",
    "    \"\"\"Function to convert Penn Treeback POS tags to WordNet.\"\"\"\n",
    "    \n",
    "    tag_dictionary = {\"NN\":\"n\", \"JJ\":\"a\",\"VB\":\"v\", \"RB\":\"r\"}\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # If the first two characters of the Penn Treebank POS tag are in the tag_dictionary \n",
    "        return tag_dictionary[penn_pos_tag[:2]]\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return \"n\" # Default to Noun if no mapping available \n",
    "    \n",
    "\n",
    "# Get list of English stop words - Define outside of function so doesn't have to process every call \n",
    "stopwords_english = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def remove_stopwords_and_lemmatise(text):\n",
    "    \"\"\"Function to tokenise a string, remove stop words, lemmatise, and return a list of words.\"\"\"\n",
    "    \n",
    "    # Check text input is a string \n",
    "    if (not isinstance(text, str)):\n",
    "        \n",
    "        raise Exception(\"text input is not a string.\")\n",
    "    \n",
    "    # Tokenise text into words \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words \n",
    "    words_filtered = [word for word in words if word not in stopwords_english]\n",
    "    \n",
    "    # TODO: Update to use full conversion table as opposed to simplified version \n",
    "    \n",
    "    # Apply POS tagging \n",
    "    words_pos_tagged = pos_tag(words_filtered)\n",
    "    \n",
    "    # Create a WordNetLemmatizer object \n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    # Define empty lemmas list \n",
    "    lemmas = []\n",
    "    \n",
    "    # Loop through words in sentence and lemmatise \n",
    "    for word, tag in words_pos_tagged:\n",
    "        \n",
    "        lemmas.append(wnl.lemmatize(word, pos = penn_to_wordnet(tag)))\n",
    "    \n",
    "    return lemmas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "        \n",
    "    # Split data into training (70%) and test (30%) splits \n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(food_reviews_data[\"Text\"], food_reviews_data[\"Score\"], \n",
    "                                                                        test_size = 0.3, random_state = 123, \n",
    "                                                                        stratify = food_reviews_data[\"Score\"])\n",
    "    \n",
    "    train_labels = train_labels.tolist()\n",
    "    \n",
    "    test_labels = test_labels.tolist()\n",
    "    \n",
    "    # TODO: Decide if it should be stratified random sampling or random sampling \n",
    "    \n",
    "    # TODO: Remove the seed as it should not be used for real evaluation of model performance \n",
    "    \n",
    "    # Remove stop words from train data and lemmatise \n",
    "    train_data_tokenised = train_data.apply(remove_stopwords_and_lemmatise)\n",
    "    \n",
    "    # Join lists of lemmas to string (need both ways) \n",
    "    train_data = [\" \".join(lemmas) for lemmas in train_data_tokenised]\n",
    "    \n",
    "    # Remove stop words from test data and lemmatise \n",
    "    test_data_tokenised = test_data.apply(remove_stopwords_and_lemmatise)\n",
    "    \n",
    "    # Join lists of lemmas to string (need both ways) \n",
    "    test_data = [\" \".join(lemmas) for lemmas in test_data_tokenised]\n",
    "    \n",
    "    # Save tokenised train data to csv \n",
    "    train_data_tokenised_csv = pd.Series(train_data_tokenised)\n",
    "    train_data_tokenised_csv.to_csv(\"train_data_tokenised.csv\")\n",
    "    \n",
    "    # Save train data to csv \n",
    "    train_data_csv = pd.DataFrame({\"Text\" : train_data, \n",
    "                                   \"Score\" : train_labels})\n",
    "    train_data_csv.to_csv(\"train_data.csv\")\n",
    "    \n",
    "    # Save tokenised test data to csv \n",
    "    test_data_tokenised_csv = pd.Series(test_data_tokenised)\n",
    "    test_data_tokenised_csv.to_csv(\"test_data_tokenised.csv\")\n",
    "    \n",
    "    # Save test data to csv \n",
    "    test_data_csv = pd.DataFrame({\"Text\" : test_data, \n",
    "                                  \"Score\" : test_labels})\n",
    "    test_data_csv.to_csv(\"test_data.csv\")\n",
    "    \n",
    "if (load_preprocessed_data == True):\n",
    "    \n",
    "    # Load preprocessed tokenised train data \n",
    "    train_data_tokenised = pd.read_csv(\"train_data_tokenised.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    train_data_tokenised = [ast.literal_eval(text) for text in train_data_tokenised]\n",
    "    \n",
    "    # Load preprocessed train data \n",
    "    train_data = pd.read_csv(\"train_data.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    \n",
    "    # Load train labels \n",
    "    train_labels = pd.read_csv(\"train_data.csv\", index_col = 0)[\"Score\"].tolist()\n",
    "    \n",
    "    # Load preprocessed tokenised test data \n",
    "    test_data_tokenised = pd.read_csv(\"test_data_tokenised.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    test_data_tokenised = [ast.literal_eval(text) for text in test_data_tokenised]\n",
    "    \n",
    "    # Load preprocessed test data \n",
    "    test_data = pd.read_csv(\"test_data.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    \n",
    "    # Load train labels \n",
    "    test_labels = pd.read_csv(\"test_data.csv\", index_col = 0)[\"Score\"].tolist()\n",
    "    \n",
    "# TODO: Check if any list items are empty strings \n",
    "    \n",
    "# TODO: Save using pickle instead of csv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the frequency of Score values for the entire dataset \n",
    "all_scores = pd.Series(train_labels + test_labels)\n",
    "all_frequencies = all_scores.value_counts()\n",
    "all_frequencies = all_frequencies.reset_index()\n",
    "all_frequencies.columns = [\"Score\", \"Frequency\"]\n",
    "\n",
    "plt.figure(figsize = (6, 4), dpi = 100)\n",
    "plt.bar(all_frequencies[\"Score\"], all_frequencies[\"Frequency\"], color = \"skyblue\", edgecolor = \"black\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Frequency of Food Review Scores - Full Dataset Deduplicated\")\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_color(\"black\")\n",
    "ax.spines[\"right\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "plt.savefig(\"Figure_1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the frequency of Score values for the train dataset \n",
    "train_scores = pd.Series(train_labels)\n",
    "train_frequencies = train_scores.value_counts()\n",
    "train_frequencies = train_frequencies.reset_index()\n",
    "train_frequencies.columns = [\"Score\", \"Frequency\"]\n",
    "\n",
    "plt.figure(figsize = (6, 4), dpi = 100)\n",
    "plt.bar(train_frequencies[\"Score\"], train_frequencies[\"Frequency\"], color = \"skyblue\", edgecolor = \"black\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Frequency of Food Review Scores - Train Dataset\")\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_color(\"black\")\n",
    "ax.spines[\"right\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the frequency of Score values for the test dataset \n",
    "test_scores = pd.Series(test_labels)\n",
    "test_frequencies = test_scores.value_counts()\n",
    "test_frequencies = test_frequencies.reset_index()\n",
    "test_frequencies.columns = [\"Score\", \"Frequency\"]\n",
    "\n",
    "plt.figure(figsize = (6, 4), dpi = 100)\n",
    "plt.bar(test_frequencies[\"Score\"], test_frequencies[\"Frequency\"], color = \"skyblue\", edgecolor = \"black\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Frequency of Food Review Scores - Test Dataset\")\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_color(\"black\")\n",
    "ax.spines[\"right\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cee84be8ff5d30b3cc777f43b92b5b69",
     "grade": false,
     "grade_id": "cell-b691a7bc111d2ca5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 2\n",
    "Implement a Naïve Bayes model for predicting the rating of a food review. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**5%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "638739c81d3d084fbcc8233bbecb6b02",
     "grade": true,
     "grade_id": "cell-c7228a828210126a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (load_NB != True):\n",
    "    \n",
    "    # Naive Bayes model - input is converted to TF-IDF vectors and then Multinomial Naive Bayes is used \n",
    "    nb_model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "    \n",
    "    # Tune model for best value of alpha (lapace smoothing parameter) using 5-fold cross-validation \n",
    "    # More coarse grid searching was undertaken initially to narrow down to the below range \n",
    "    grid = {\"multinomialnb__alpha\" : [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]}\n",
    "    \n",
    "    grid_search = GridSearchCV(nb_model, grid, cv = 5, scoring = \"accuracy\")\n",
    "    \n",
    "    # TODO: Decide if F1-Score better \n",
    "    \n",
    "    # TODO: Decide if adding fit_prior to the grid search makes sense \n",
    "    \n",
    "    grid_search.fit(train_data, train_labels)\n",
    "    \n",
    "    best_alpha = grid_search.best_params_[\"multinomialnb__alpha\"]\n",
    "    \n",
    "    print(best_alpha)\n",
    "    \n",
    "    nb_model.set_params(multinomialnb__alpha = best_alpha)\n",
    "    \n",
    "    # Train model \n",
    "    nb_model.fit(train_data, train_labels)\n",
    "    \n",
    "    # Save model \n",
    "    nb_model_filename = \"nb_model.pkl\"\n",
    "    \n",
    "    with open(nb_model_filename, \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(nb_model, file)\n",
    "\n",
    "if (load_NB == True):\n",
    "    \n",
    "    # Load model \n",
    "    with open(\"nb_model.pkl\", \"rb\") as file:\n",
    "        \n",
    "        nb_model = pickle.load(file)\n",
    "    \n",
    "# Test model \n",
    "nb_predictions = nb_model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels, nb_predictions)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "           xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels, nb_predictions))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a8672a0a32389c7076c73d1de3acfb1",
     "grade": false,
     "grade_id": "cell-bd3fe708de79e951",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 3\n",
    "Implement a k-Nearest Neighbours model for predicting the rating of a food review. Train your model on the training set and test it on the test set. Use an appropriate text representation. You must select the best k by examining the performance of the model for $k \\in \\{1,3,5,7\\}$, using an appropriate cross-validation approach. Create a plot for k vs. classification performance to justify your choice. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_precalculated_w2v_embeddings_300 != True):\n",
    "    \n",
    "    # Train word2vec word embedding model using train data to create denser vectors  \n",
    "    w2v_word_embeddings_300 = gensim.models.Word2Vec(train_data_tokenised, vector_size = 300, window = 5, \n",
    "                                                 min_count = 1, sg = 0, seed = 123)\n",
    "        \n",
    "    # Save word2vec word embeddings \n",
    "    w2v_word_embeddings_300.save(\"w2v_word_embeddings_300.model\")\n",
    "    \n",
    "# TODO: Explain why vector_size and window chosen \n",
    "\n",
    "if (load_precalculated_w2v_embeddings_300 == True):\n",
    "    \n",
    "    # Load word2vec word embeddings \n",
    "    w2v_word_embeddings_300 = Word2Vec.load(\"w2v_word_embeddings_300.model\")\n",
    "    \n",
    "\n",
    "def text_to_single_vector(text, w2v_word_embeddings):\n",
    "    \"\"\"Function to trasform document (a review) in the form of a list of words into a single vector \n",
    "    representation which is the average vector representation of the embedded words in the review.\"\"\"\n",
    "    \n",
    "    # Check text input is a list  \n",
    "    if (not isinstance(text, list)):\n",
    "        \n",
    "        raise Exception(\"text input is not a list.\")\n",
    "    \n",
    "    vector = sum(w2v_word_embeddings.wv[word] for word in text if word in w2v_word_embeddings.wv) / len(text)\n",
    "    \n",
    "    return vector\n",
    "\n",
    "\n",
    "if (load_precalculated_w2v_docs_vectorised != True):\n",
    "    \n",
    "    # Vectorise train data into dense vector document representations \n",
    "    train_data_w2v_docs_vectorised = [text_to_single_vector(text, w2v_word_embeddings_300) for text in train_data_tokenised]\n",
    "    \n",
    "    # Vectorise test data into dense vector document representations \n",
    "    test_data_w2v_docs_vectorised = [text_to_single_vector(text, w2v_word_embeddings_300) for text in test_data_tokenised]\n",
    "    \n",
    "    # Save vectorised document representations \n",
    "    with open(\"train_data_w2v_docs_vectorised.pkl\", \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(train_data_w2v_docs_vectorised, file)\n",
    "        \n",
    "    # Save vectorised document representations \n",
    "    with open(\"test_data_w2v_docs_vectorised.pkl\", \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(test_data_w2v_docs_vectorised, file)\n",
    "        \n",
    "if (load_precalculated_w2v_docs_vectorised == True):\n",
    "    \n",
    "    # Load vectorised document representations \n",
    "    with open(\"train_data_w2v_docs_vectorised.pkl\", \"rb\") as file:\n",
    "    \n",
    "        train_data_w2v_docs_vectorised = pickle.load(file)\n",
    "    \n",
    "    # Load vectorised document representations \n",
    "    with open(\"test_data_w2v_docs_vectorised.pkl\", \"rb\") as file:\n",
    "    \n",
    "        test_data_w2v_docs_vectorised = pickle.load(file)\n",
    "    \n",
    "if (run_kNN == True):\n",
    "    \n",
    "    if (run_kNN_cross_validation == True):\n",
    "        \n",
    "        # Values of k to test \n",
    "        k_values = [1, 3, 5, 7]\n",
    "        \n",
    "        mean_accuracies = []\n",
    "        \n",
    "        for k in k_values:\n",
    "            \n",
    "            knn_model = KNeighborsClassifier(n_neighbors = k)\n",
    "            \n",
    "            scores = cross_val_score(knn_model, train_data_w2v_docs_vectorised, train_labels, cv = 5, scoring = \"accuracy\")\n",
    "            \n",
    "            # TODO: Explain why Accuracy vs F1-Score - If doing class balanced sampling then doesn't matter, \n",
    "            # if not then F1-Score makes most sense because of class imbalance \n",
    "            \n",
    "            # TODO: Decide on if to tune for weights and metric parameters too \n",
    "            \n",
    "            mean_accuracy = scores.mean()\n",
    "            \n",
    "            mean_accuracies.append(mean_accuracy)\n",
    "            \n",
    "        # Save cross-validation accuracies  \n",
    "        with open(\"knn_mean_accuracies.pkl\", \"wb\") as file:\n",
    "            \n",
    "            pickle.dump(mean_accuracies, file)\n",
    "            \n",
    "    if (run_kNN_cross_validation != True): # TODO: Run kNN training again to save mean accuracies \n",
    "        \n",
    "        # Load cross-validation accuracies  \n",
    "        with open(\"knn_mean_accuracies.pkl\", \"rb\") as file:\n",
    "            \n",
    "            mean_accuracies = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7c5809dc4f4de2b111845abdcf40ddf",
     "grade": true,
     "grade_id": "cell-e566d393c7fac970",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    k_values = [1, 3, 5, 7]\n",
    "    \n",
    "    plt.figure(figsize = (6, 4), dpi = 100)\n",
    "    plt.plot(k_values, mean_accuracies, marker = \"o\", linestyle = \"-\", color = \"b\")\n",
    "    plt.title(\"kNN Model Performance by Number of Neighbours\")\n",
    "    plt.xlabel(\"Number of Neighbours (k)\")\n",
    "    plt.ylabel(\"Mean Accuracy\")\n",
    "    plt.xticks(k_values)\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_color(\"black\")\n",
    "    ax.spines[\"right\"].set_color(\"black\")\n",
    "    ax.spines[\"left\"].set_color(\"black\")\n",
    "    ax.spines[\"bottom\"].set_color(\"black\")\n",
    "    plt.savefig(\"Figure_2.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN == True):\n",
    "    \n",
    "    if (load_kNN != True):\n",
    "        \n",
    "        k_values = [1, 3, 5, 7]\n",
    "        \n",
    "        # k Nearest Neighbours model - input is converted to TF-IDF vectors and then kNN is used \n",
    "        # The k value which produced the hgihest accuracy from cross-validation on the train/validation set is used \n",
    "        knn_model = KNeighborsClassifier(n_neighbors = k_values[mean_accuracies.index(max(mean_accuracies))])\n",
    "        \n",
    "        # Train model \n",
    "        knn_model.fit(train_data_w2v_docs_vectorised, train_labels)\n",
    "        \n",
    "        # Save model \n",
    "        knn_model_filename = \"knn_model.pkl\"\n",
    "        \n",
    "        with open(knn_model_filename, \"wb\") as file:\n",
    "            \n",
    "            pickle.dump(knn_model, file)\n",
    "            \n",
    "    if (load_kNN == True):\n",
    "        \n",
    "        # Load model \n",
    "        with open(\"knn_model.pkl\", \"rb\") as file:\n",
    "            \n",
    "            knn_model = pickle.load(file)\n",
    "            \n",
    "    # Test model \n",
    "    knn_predictions = knn_model.predict(test_data_w2v_docs_vectorised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN == True):\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    matrix = confusion_matrix(test_labels, knn_predictions)\n",
    "    sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "                xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute and print classification performance metrics\n",
    "    print(\"Accuracy:\\t%f\" % accuracy_score(test_labels, knn_predictions))\n",
    "    print(\"F1-score:\\t%f\" % f1_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"Precision:\\t%f\" % precision_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"Recall:\\t\\t%f\" % recall_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels, knn_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43ad334a0b661041421fbde0c35614c1",
     "grade": false,
     "grade_id": "cell-ceb568d7b9979383",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 4\n",
    "Implement a Convolutional Neural Network (CNN) model for predicting the rating of a food review. The model must have at least two convolutional layers. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**13%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc79d3616790883ed0539f3416cb92ad",
     "grade": true,
     "grade_id": "cell-8062f67e02d4c61f",
     "locked": false,
     "points": 13,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the number of words in each review after preprocessing etc. \n",
    "all_data_tokenised = train_data_tokenised + test_data_tokenised\n",
    "\n",
    "n_words = [len(text) for text in all_data_tokenised]\n",
    "\n",
    "# Summary statistics for the number of words per review \n",
    "pd.Series(n_words).describe()\n",
    "\n",
    "plt.figure(figsize = (6, 4), dpi = 100)\n",
    "plt.hist(n_words, bins = range(0, 2100, 50), color = \"skyblue\", edgecolor = \"black\")\n",
    "plt.title(\"Distribution of Number of Words per Food Review after Preprocessing\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis = \"y\", alpha = 0.75)\n",
    "plt.xlim([-30, 400])\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_color(\"black\")\n",
    "ax.spines[\"right\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "plt.savefig(\"Figure_3.png\")\n",
    "plt.show()\n",
    "\n",
    "max_words = round(pd.Series(n_words).describe()[\"max\"])\n",
    "print(f\"Note: y axis limited to show only visible columns. Number of words values go as high as {max_words}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try not removing stop words and see if that increases accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_matrix(document, w2v_word_embeddings, max_length):\n",
    "    \"\"\"Function to trasform document (a review) in the form of a list of words into a matrix of \n",
    "    vector representations, until the specified max length.\"\"\"\n",
    "    \n",
    "    # TODO: Add checks \n",
    "    \n",
    "    matrix = np.zeros((max_length, 50))\n",
    "    \n",
    "    for i, word in enumerate(document):\n",
    "        \n",
    "        if i >= max_length:\n",
    "            \n",
    "            break\n",
    "            \n",
    "        if word in w2v_word_embeddings.wv:\n",
    "            \n",
    "            matrix[i] = w2v_word_embeddings.wv[word]\n",
    "            \n",
    "    return matrix\n",
    "    \n",
    "    \n",
    "if (load_precalculated_w2v_embeddings_50 != True):\n",
    "    \n",
    "    # Train word2vec word embedding model using train data to create denser vectors  \n",
    "    w2v_word_embeddings_50 = gensim.models.Word2Vec(train_data_tokenised, vector_size = 50, window = 5, \n",
    "                                                 min_count = 1, sg = 0, seed = 123)\n",
    "        \n",
    "    # Save word2vec word embeddings \n",
    "    w2v_word_embeddings_50.save(\"w2v_word_embeddings_50.model\")\n",
    "    \n",
    "# TODO: Explain why vector_size and window chosen \n",
    "\n",
    "if (load_precalculated_w2v_embeddings_50 == True):\n",
    "    \n",
    "    # Load word2vec word embeddings \n",
    "    w2v_word_embeddings_50 = Word2Vec.load(\"w2v_word_embeddings_50.model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_precalculated_w2v_words_vectorised != True):\n",
    "    \n",
    "    # Vectorise train data into dense vector word representations and combine into a \n",
    "    # list of dense matrix document representations\n",
    "    train_data_w2v_words_vectorised = [document_to_matrix(text, w2v_word_embeddings_50, 50) for text in train_data_tokenised]\n",
    "    \n",
    "    # Vectorise test data into dense vector word representations and combine into a \n",
    "    # list of dense matrix document representations\n",
    "    test_data_w2v_words_vectorised = [document_to_matrix(text, w2v_word_embeddings_50, 50) for text in test_data_tokenised]\n",
    "    \n",
    "    # TODO: Explain why 100 max length \n",
    "    \n",
    "    # Save vectorised word representations \n",
    "    with open(\"train_data_w2v_words_vectorised.pkl\", \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(train_data_w2v_words_vectorised, file)\n",
    "        \n",
    "    # Save vectorised word representations \n",
    "    with open(\"test_data_w2v_words_vectorised.pkl\", \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(test_data_w2v_words_vectorised, file)\n",
    "\n",
    "if (load_precalculated_w2v_words_vectorised == True):\n",
    "    \n",
    "    if (load_CNN != True | load_LSTM != True):\n",
    "        \n",
    "        # Load vectorised word representations \n",
    "        with open(\"train_data_w2v_words_vectorised.pkl\", \"rb\") as file:\n",
    "        \n",
    "            train_data_w2v_words_vectorised = pickle.load(file)\n",
    "    \n",
    "    # Load vectorised word representations \n",
    "    with open(\"test_data_w2v_words_vectorised.pkl\", \"rb\") as file:\n",
    "    \n",
    "        test_data_w2v_words_vectorised = pickle.load(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_CNN != True):\n",
    "    \n",
    "    embedding_size = (50, 50)\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n",
    "    \n",
    "    cnn_model = models.Sequential()\n",
    "    \n",
    "    cnn_model.add(layers.Conv1D(filters = 128, kernel_size = 5, activation = \"relu\", input_shape = embedding_size))\n",
    "    cnn_model.add(layers.MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(layers.Conv1D(filters = 128, kernel_size = 5, activation = \"relu\"))\n",
    "    cnn_model.add(layers.GlobalMaxPooling1D())\n",
    "    cnn_model.add(layers.Dense(units = 128, activation = \"relu\"))\n",
    "    cnn_model.add(layers.Dense(5, activation = \"softmax\"))\n",
    "    \n",
    "    cnn_model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimiser, metrics = [\"accuracy\"])\n",
    "\n",
    "train_labels_minus1 = [score - 1 for score in train_labels]\n",
    "\n",
    "test_labels_minus1 = [score - 1 for score in test_labels]\n",
    "\n",
    "if (load_CNN != True):\n",
    "    \n",
    "    epochs = 10\n",
    "    \n",
    "    early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, restore_best_weights = True, mode = \"auto\")\n",
    "    \n",
    "    x_train = np.array(train_data_w2v_words_vectorised)\n",
    "    y_train = np.array(train_labels_minus1)\n",
    "    \n",
    "    cnn_history = cnn_model.fit(x = x_train, y = y_train, validation_split = 0.3, epochs = epochs, callbacks = [early], verbose = 2)\n",
    "    \n",
    "    # Save model \n",
    "    cnn_model_filename = \"cnn_model_3.pkl\"\n",
    "    \n",
    "    with open(cnn_model_filename, \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(cnn_model, file)\n",
    "        \n",
    "    # Save training history \n",
    "    cnn_model_history_filename = \"cnn_model_history_3.pkl\"\n",
    "    \n",
    "    with open(cnn_model_history_filename, \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(cnn_history, file)\n",
    "        \n",
    "if (load_CNN == True):\n",
    "    \n",
    "    # Load model \n",
    "    with open(\"cnn_model_3.pkl\", \"rb\") as file:\n",
    "        \n",
    "        cnn_model = pickle.load(file)\n",
    "        \n",
    "    # Load training history \n",
    "    with open(\"cnn_model_history_3.pkl\", \"rb\") as file:\n",
    "        \n",
    "        cnn_history = pickle.load(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize = (8, 6), dpi = 100, sharex = True)\n",
    "fig.suptitle(\"Convolutional Neural Network Training\", fontsize = 14, color = \"black\")\n",
    "ax1.set_ylim([0, 1.01])\n",
    "ax1.plot(cnn_history.history[\"val_accuracy\"], \"b\")\n",
    "ax1.set_ylabel(\"Accuracy\", color = \"black\")\n",
    "ax1.plot(cnn_history.history[\"accuracy\"], \"r\")\n",
    "ax1.legend([\"Validation\", \"Training\"])\n",
    "ax1.spines[\"top\"].set_color(\"black\")\n",
    "ax1.spines[\"right\"].set_color(\"black\")\n",
    "ax1.spines[\"left\"].set_color(\"black\")\n",
    "ax1.spines[\"bottom\"].set_color(\"black\")\n",
    "ax1.tick_params(axis = \"x\", colors = \"black\")\n",
    "ax1.tick_params(axis = \"y\", colors = \"black\")\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.plot(cnn_history.history[\"val_loss\"], \"b\")\n",
    "ax2.plot(cnn_history.history[\"loss\"], \"r\")\n",
    "ax2.set_ylabel(\"Loss\", color = \"black\")\n",
    "ax2.set_xlabel(\"Epochs\", color = \"black\")\n",
    "ax2.legend([\"Validation\", \"Training\"])\n",
    "ax2.spines[\"top\"].set_color(\"black\")\n",
    "ax2.spines[\"right\"].set_color(\"black\")\n",
    "ax2.spines[\"left\"].set_color(\"black\")\n",
    "ax2.spines[\"bottom\"].set_color(\"black\")\n",
    "ax2.tick_params(axis = \"x\", colors = \"black\")\n",
    "ax2.tick_params(axis = \"y\", colors = \"black\")\n",
    "plt.savefig(\"Figure_4.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model \n",
    "cnn_predictions = cnn_model.predict(np.array(test_data_w2v_words_vectorised))\n",
    "\n",
    "cnn_predictions_labels = np.argmax(cnn_predictions, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix \n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels_minus1, cnn_predictions_labels)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "            xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels_minus1, cnn_predictions_labels))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels_minus1, cnn_predictions_labels, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels_minus1, cnn_predictions_labels, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels_minus1, cnn_predictions_labels, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels_minus1, cnn_predictions_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74843fe33a4f86a21469871aac52bb90",
     "grade": false,
     "grade_id": "cell-a985e9ca1140281d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 5\n",
    "Implement a Recurrent Neural Network (RNN) or a Long Short-Term Memory (LSTM) model for predicting the rating of a food review. The model must have at least two RNN/LSTM layers. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**12%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb7179dcc099d3d51db8e0d4d4c53c7b",
     "grade": true,
     "grade_id": "cell-76f081948cba4b02",
     "locked": false,
     "points": 12,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (load_LSTM != True):\n",
    "    \n",
    "    embedding_size = (50, 50)\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n",
    "    \n",
    "    lstm_model = models.Sequential()\n",
    "    \n",
    "    lstm_model.add(layers.Masking(mask_value = 0., input_shape = embedding_size))\n",
    "    lstm_model.add(layers.Bidirectional(layers.LSTM(units = 64, return_sequences = True)))\n",
    "    lstm_model.add(layers.Bidirectional(layers.LSTM(units = 64, go_backwards = True, dropout = 0.2)))\n",
    "    lstm_model.add(layers.Dense(units = 64, activation = \"relu\"))\n",
    "    lstm_model.add(layers.Dense(5, activation = \"softmax\"))\n",
    "    \n",
    "    lstm_model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimiser, metrics = [\"accuracy\"])\n",
    "\n",
    "train_labels_minus1 = [score - 1 for score in train_labels]\n",
    "\n",
    "test_labels_minus1 = [score - 1 for score in test_labels]\n",
    "\n",
    "if (load_LSTM != True):\n",
    "    \n",
    "    epochs = 10\n",
    "    \n",
    "    early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, restore_best_weights = True, mode = \"auto\")\n",
    "    \n",
    "    x_train = np.array(train_data_w2v_words_vectorised)\n",
    "    y_train = np.array(train_labels_minus1)\n",
    "    \n",
    "    lstm_history = lstm_model.fit(x = x_train, y = y_train, validation_split = 0.3, epochs = epochs, callbacks = [early], verbose = 2)\n",
    "    \n",
    "    # Save model \n",
    "    lstm_model_filename = \"lstm_model_2.pkl\"\n",
    "    \n",
    "    with open(lstm_model_filename, \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(lstm_model, file)\n",
    "        \n",
    "    # Save training history \n",
    "    lstm_model_history_filename = \"lstm_model_history_2.pkl\"\n",
    "    \n",
    "    with open(lstm_model_history_filename, \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(lstm_history, file)\n",
    "        \n",
    "if (load_LSTM == True):\n",
    "    \n",
    "    # Load model \n",
    "    with open(\"lstm_model_2.pkl\", \"rb\") as file:\n",
    "        \n",
    "        lstm_model = pickle.load(file)\n",
    "        \n",
    "    # Load training history \n",
    "    with open(\"lstm_model_history_2.pkl\", \"rb\") as file:\n",
    "        \n",
    "        lstm_history = pickle.load(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize = (8, 6), dpi = 100, sharex = True)\n",
    "fig.suptitle(\"Long Short-Term Memory Model Training\", fontsize = 14, color = \"black\")\n",
    "ax1.set_ylim([0, 1.01])\n",
    "ax1.plot(lstm_history.history[\"val_accuracy\"], \"b\")\n",
    "ax1.set_ylabel(\"Accuracy\", color = \"black\")\n",
    "ax1.plot(lstm_history.history[\"accuracy\"], \"r\")\n",
    "ax1.legend([\"Validation\", \"Training\"])\n",
    "ax1.spines[\"top\"].set_color(\"black\")\n",
    "ax1.spines[\"right\"].set_color(\"black\")\n",
    "ax1.spines[\"left\"].set_color(\"black\")\n",
    "ax1.spines[\"bottom\"].set_color(\"black\")\n",
    "ax1.tick_params(axis = \"x\", colors = \"black\")\n",
    "ax1.tick_params(axis = \"y\", colors = \"black\")\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.plot(lstm_history.history[\"val_loss\"], \"b\")\n",
    "ax2.plot(lstm_history.history[\"loss\"], \"r\")\n",
    "ax2.set_ylabel(\"Loss\", color = \"black\")\n",
    "ax2.set_xlabel(\"Epochs\", color = \"black\")\n",
    "ax2.legend([\"Validation\", \"Training\"])\n",
    "ax2.spines[\"top\"].set_color(\"black\")\n",
    "ax2.spines[\"right\"].set_color(\"black\")\n",
    "ax2.spines[\"left\"].set_color(\"black\")\n",
    "ax2.spines[\"bottom\"].set_color(\"black\")\n",
    "ax2.tick_params(axis = \"x\", colors = \"black\")\n",
    "ax2.tick_params(axis = \"y\", colors = \"black\")\n",
    "plt.savefig(\"Figure_5.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model \n",
    "lstm_predictions = lstm_model.predict(np.array(test_data_w2v_words_vectorised))\n",
    "\n",
    "lstm_predictions_labels = np.argmax(lstm_predictions, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix \n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels_minus1, lstm_predictions_labels)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "            xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels_minus1, lstm_predictions_labels))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels_minus1, lstm_predictions_labels, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels_minus1, lstm_predictions_labels, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels_minus1, lstm_predictions_labels, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels_minus1, lstm_predictions_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5e477712b6bad9901556381dd829392",
     "grade": false,
     "grade_id": "cell-9f3d1c8c43462384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 6\n",
    "Compute the confusion matrix, accuracy, F1-score, precision and recall for each model. (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5080f7d517214809afe68eee9318b427",
     "grade": true,
     "grade_id": "cell-b3a9e53040d493c1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes \n",
    "\n",
    "# Plot the confusion matrix\n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels, nb_predictions)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "           xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.savefig(\"Figure_6_2.png\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels, nb_predictions))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbours \n",
    "\n",
    "if (run_kNN == True):\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    matrix = confusion_matrix(test_labels, knn_predictions)\n",
    "    sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "                xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"Predicted label\")\n",
    "    plt.savefig(\"Figure_7_2.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute and print classification performance metrics\n",
    "    print(\"Accuracy:\\t%f\" % accuracy_score(test_labels, knn_predictions))\n",
    "    print(\"F1-score:\\t%f\" % f1_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"Precision:\\t%f\" % precision_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"Recall:\\t\\t%f\" % recall_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels, knn_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network \n",
    "\n",
    "# Plot the confusion matrix \n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels_minus1, cnn_predictions_labels)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "            xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.savefig(\"Figure_8_2.png\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels_minus1, cnn_predictions_labels))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels_minus1, cnn_predictions_labels, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels_minus1, cnn_predictions_labels, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels_minus1, cnn_predictions_labels, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels_minus1, cnn_predictions_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Short-Term Memory model \n",
    "\n",
    "# Plot the confusion matrix \n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels_minus1, lstm_predictions_labels)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "            xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.savefig(\"Figure_9_2.png\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels_minus1, lstm_predictions_labels))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels_minus1, lstm_predictions_labels, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels_minus1, lstm_predictions_labels, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels_minus1, lstm_predictions_labels, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels_minus1, lstm_predictions_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9def807c7734179b60c1d5121bbbd436",
     "grade": false,
     "grade_id": "cell-290a6e3bf464e305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 7\n",
    "Store the **four** trained models in files and implement a function `predict_food_review(text, model)` that given a <ins>text string</ins> (“`text`”) and model <ins>filename</ins> (“`model`”), it will load the pre-trained model, and predict the food review rating of the input text. The function should be able to work without requiring to rerun all or part of your code. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03a2117734166d6e91043d88d5c5ef8a",
     "grade": true,
     "grade_id": "cell-f384d017d7d6ac75",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function works under the assumption that all the required packages above are loaded \n",
    "\n",
    "# TODO: Decide if loading packages within the function so it is completely self contained makes sense \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Function to clean text input to ensure input strings are processed in the same way as for \n",
    "    model train and test data.\"\"\"\n",
    "    \n",
    "    # Note: code here is different to preprocessing in the main script as the latter is for processing whole \n",
    "    # pandas series and the former is individual stings. The results are identical. \n",
    "    \n",
    "    # Check text input is a string \n",
    "    if (not isinstance(text, str)):\n",
    "        \n",
    "        raise Exception(\"text input is not a string.\")\n",
    "    \n",
    "    # Transform text to all lowercase \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove all \"-\", \".\", \"'\" and replace with \"\" e.g. lower-case to lowercase, U.K to UK, don't to dont \n",
    "    text = re.sub(r\"[-.']\", \"\", text)\n",
    "    \n",
    "    # Replace html tags with \" \" \n",
    "    text = re.sub(r\"<.+?>\", \" \", text)\n",
    "    \n",
    "    # Replace happy emojis with \" happy \" \n",
    "    text = re.sub(r\"[:][)]|[(][:]\", \" happy \", text)\n",
    "    \n",
    "    # Replace sad emojis with \" sad \" \n",
    "    text = re.sub(r\"[:][(]|[)][:]\", \" sad \", text)\n",
    "    \n",
    "    # Remove punctuation \n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def predict_food_review(text, model):\n",
    "    \"\"\"Function to predict the Score (1 to 5) of a food review using pretrained Naive Bayes, k Nearest Neighbours, \n",
    "    Convolutional Neural Network, and Long Short-Term Memory models. Provide input text as a string. \n",
    "    Choose models from: \"nb_model.pkl\", \"knn_model.pkl\", \"cnn_model.pkl\", and \"lstm_model.pkl\".\"\"\"\n",
    "    \n",
    "    # TODO: Make variable and file naming consistent \n",
    "    \n",
    "    # Check text input is a string \n",
    "    if (not isinstance(text, str)):\n",
    "        \n",
    "        raise Exception(\"text input is not a string.\")\n",
    "        \n",
    "    # Check model filename input is a string \n",
    "    if (not isinstance(model, str)):\n",
    "        \n",
    "        raise Exception(\"model filename input is not a string.\")\n",
    "        \n",
    "    # Check a valid model filename input is provided \n",
    "    valid_model_filenames = [\"nb_model.pkl\", \"knn_model.pkl\", \"cnn_model.pkl\", \"lstm_model.pkl\"]\n",
    "    \n",
    "    if (not model in valid_model_filenames):\n",
    "        \n",
    "        raise Exception(\"model filename input is not a valid option. \\nValid options include: \\n'nb_model.pkl', 'kNN_model.pkl', 'cnn_model.pkl', and 'lstm_model.pkl'\")\n",
    "    \n",
    "    # Clean text in the same way as for initial train and test \n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # POS tag, remove stop words, and lemmatise in the same way as for initial train and test and return a list of lemmas \n",
    "    text = remove_stopwords_and_lemmatise(text)\n",
    "    \n",
    "    # Naive Bayes \n",
    "    if (model == \"nb_model.pkl\"):\n",
    "        \n",
    "        # Join lists of lemmas to string \n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        # Make text an element of a list - required for predict() \n",
    "        text = [text]\n",
    "        \n",
    "        # Load Naive Bayes model \n",
    "        with open(\"nb_model.pkl\", \"rb\") as file:\n",
    "            \n",
    "            nb_model = pickle.load(file)\n",
    "            \n",
    "        # Returns np array \n",
    "        predicted_score = nb_model.predict(text)\n",
    "        \n",
    "        # Extract element from array and convert to string \n",
    "        predicted_score = str(predicted_score.item())\n",
    "        \n",
    "        return predicted_score\n",
    "    \n",
    "    # k Nearest Neighbours \n",
    "    if (model == \"knn_model.pkl\"):\n",
    "        \n",
    "        # Load word2vec word embeddings \n",
    "        w2v_word_embeddings_300 = Word2Vec.load(\"w2v_word_embeddings_300.model\")\n",
    "        \n",
    "        # Vectorise text into a dense vector document representation \n",
    "        text = [text_to_single_vector(text, w2v_word_embeddings_300)]\n",
    "        \n",
    "        # Load k Nearest Neighbours \n",
    "        with open(\"knn_model.pkl\", \"rb\") as file:\n",
    "            \n",
    "            knn_model = pickle.load(file)\n",
    "            \n",
    "        # Returns np array \n",
    "        predicted_score = knn_model.predict(text)\n",
    "        \n",
    "        # Extract element from array and convert to string \n",
    "        predicted_score = str(predicted_score.item())\n",
    "        \n",
    "        return predicted_score\n",
    "        \n",
    "    # Convolutional Neural Network \n",
    "    if (model == \"cnn_model.pkl\"):\n",
    "        \n",
    "        # Load word2vec word embeddings \n",
    "        w2v_word_embeddings_50 = Word2Vec.load(\"w2v_word_embeddings_50.model\")\n",
    "        \n",
    "        # Vectorise text data into dense vector word representations \n",
    "        text = np.array([document_to_matrix(text, w2v_word_embeddings_50, 50)])\n",
    "        \n",
    "        # Load Convolutional Neural Network \n",
    "        with open(\"cnn_model.pkl\", \"rb\") as file:\n",
    "            \n",
    "            cnn_model = pickle.load(file)\n",
    "            \n",
    "        # Returns np array \n",
    "        predicted_score = cnn_model.predict(text)\n",
    "        predicted_score = np.argmax(predicted_score, axis = 1)\n",
    "        \n",
    "        # Extract element from array and convert to string \n",
    "        predicted_score = str(predicted_score.item() + 1) # Add 1 to turn 0 indexed predictions into 1-5 predictions \n",
    "        \n",
    "        return predicted_score\n",
    "    \n",
    "    # Long Short-Term Memory model \n",
    "    if (model == \"lstm_model.pkl\"):\n",
    "        \n",
    "        # Load word2vec word embeddings \n",
    "        w2v_word_embeddings_50 = Word2Vec.load(\"w2v_word_embeddings_50.model\")\n",
    "        \n",
    "        # Vectorise text data into dense vector word representations \n",
    "        text = np.array([document_to_matrix(text, w2v_word_embeddings_50, 50)])\n",
    "        \n",
    "        # Load Convolutional Neural Network \n",
    "        with open(\"lstm_model.pkl\", \"rb\") as file:\n",
    "            \n",
    "            lstm_model = pickle.load(file)\n",
    "            \n",
    "        # Returns np array \n",
    "        predicted_score = lstm_model.predict(text)\n",
    "        predicted_score = np.argmax(predicted_score, axis = 1)\n",
    "        \n",
    "        # Extract element from array and convert to string \n",
    "        predicted_score = str(predicted_score.item() + 1) # Add 1 to turn 0 indexed predictions into 1-5 predictions \n",
    "        \n",
    "        return predicted_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords.words(\"english\") # TODO: Remove negating stop words? \n",
    "\n",
    "# TODO: Ensure final function loads correct model versions and remove all _1 and _2 versions from working directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66fe20bf6b18e122ab5eb3a8110ee13b",
     "grade": false,
     "grade_id": "cell-3632d0c81d039058",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 1\n",
    "Critical discussion about the dataset (suitability, problems, class balance, etc.). (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The food review dataset used for this report contained 3 features (columns) and 540,031 observations (rows), with 162,009 duplicate rows. The dataset was deemed large enough to undertake meaningful sentiment analysis with a large vocabulary of words in the dataset in theory allowing models trained on it to generalise well to unseen data. The dataset was large enough that both the space and time complexity of data processing and modelling needed to be carefully considered to prevent running out of memory and prohibitively long run times respectively. The datasets 3 features were \"Score\": the food review score, \"Summary\": a summary of the food review, and \"Text\" the food review itself. There were no missing values in the Score or Text columns. There were 27 missing values in the Summary column, however this was not assessed to be an issue as the primary columns required were Score and Text. There were no unexpected values in the Score column (only 1-5 scores), however there was class imbalance present with scores of 5 far more prevelant than other scores which could potentially bias models to the majority class, see Figure 1. The Text column contained raw text which had not been preprocessed or tokenised, containing: HTML tags, punctuation, emojis, capital letters, etc. \n",
    "\n",
    "While the potential problems detailed above could provide challenges for undertaking sentiment analysis, it was determined that with effective mitigation the dataset was suitable for undertaking the task of predicting food review scores. \n",
    "\n",
    "__Figure 1.__\n",
    "![Figure 1.](Figure_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c04a7d6b4dc1614cce18ae7dc9b59ee0",
     "grade": true,
     "grade_id": "cell-723b0c0e08ba0f30",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- Dataset has 3 features and 540,031 observations - this is large enough for meaningful sentiment analysis to be undertaken and large enough that the computational complexity of data processing and modelling methods needed to be considered to prevent prohibitively long run times. \n",
    "- No missing values in Score column. \n",
    "- No missing values in Text column. \n",
    "- 27 missing values in Summary column - this doesn't really matter though because we primarily care about Text and Score. \n",
    "- No unexpected values in the Score column - only 1, 2, 3, 4, 5. \n",
    "- Dataset has 162,009 duplicate rows. \n",
    "- The Text column contains raw text which is not tokenised or preprocessed: HTML tags and punctuation which need removed, emojis such as smiley faces which need removed or transformed, and raw text containing capital letters which needs to be lowercased. \n",
    "- Class imbalance with majority of observations with a Score of 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e16e80cbdb327b4bd8b3dc8644c93953",
     "grade": false,
     "grade_id": "cell-cf6f3bf73d0b219c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 2\n",
    "Description and justification of the data preparation step(s) used. (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset was deduplicated to prevent the erroneous repeated rows biasing models trained on the dataset. HTML tags were removed to reduce noise. Happy and sad emojis were tranformed into \"happy\" and \"sad\" to retain useful meaning post punctuation removal. \"-\", \".\", and \"'\" were removed and replaced with \"\" to ensure consistency on the representation of words e.g. lower-case vs lowercase, U.K. vs UK, don't vs dont. All punctuation was then removed and replaced with \" \" and all text lowercased. All these processing steps were undertaken on the Summary and Text columns to reduce noise and non-useful information. This also reduces the computational complexity due to the denser vector representations achievable by not having repeated versions of words e.g. capitalised vs not. The Summary and Text columns were then concatenated, as from manual analysis is was determined that the Summary column also contained useful information regarding the sentiment of reviews. \n",
    "\n",
    "The text was then tokenised. Stop words were removed to reduce noise and remove potentially uninformative words. This also allowed for denser vector representations to make data processing and modelling less computationally intensive, while aiming to retain useful information. A trade-off was made here with the cost of reduced computational complexity being a potential reduction in models accuracy, e.g. the removal of certain stop words like \"not\" could mean models aren't able to capture important negation information. Penn Treeback Part of Speech (POS) tagging was then applied, with tags subsequently converted to simpler WordNet POS tags. This simplification could result in a reduction in models accuracy with only Nouns, Verbs, Adverbs, and Adjectives as classes for tagging, with other word types defaulted to Nouns. Words were then lemmatised to allow for denser vector representations to make data processing and modelling less computationally intensive while aiming to retain words general meanings, e.g. \"eats\", \"eating\" to \"eat\". \n",
    "\n",
    "The dataset was split into train and test sets for modelling using a 70/30 train/test split and stratified random sampling by Score to ensure both sets had a similar distribution of Score values. Given the size of the dataset simple random sampling did generally provide similar distributions of Score values in the train and test set but it was decided it was better to guarentee a representative split. \n",
    "\n",
    "The lemmatised text was then used to calculate each of the different word or document embeddings used as inputs for the various models in this report, detailed below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d827d373523a1ebd5f7adf108d5fc5e",
     "grade": true,
     "grade_id": "cell-ff3a7a6577a764fb",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- Deduplication to prevent the data biasing the models due to erroneous repeated rows. \n",
    "- HTML tag removal, emoji transformation into words, lowercasing, -, ., and ' removal with no space, and punctuation removal to remove noise and non-useful information from the Text. This helps computationally because it will lead to denser vector representations of the text due to not repeating capitalised vs not versions of words etc. This was undertaken on both Summary and Text columns. \n",
    "- The Summary and Text columns were concatenated as from manual checking it was determined that the Summary column also contained useful information regarding the sentiment of reviews. \n",
    "- The text was then tokenised. \n",
    "- Stop words were removed to remove noise / potentially uniformative words and to create denser vectors making the processing and modelling less computationally intesive, given the relatively large dataset. A standard set of English stopwords was used from the NLTK package. There is potentially some drop in modelling accuracy in exchange for the reduced computational complexity as words such as \"not\", \"wasn't\" etc. were removed which could negate positive words and change the sentiment of reviews. \n",
    "- Penn Treeback POS tagging was then applied with tags subsequently converted to simpler WordNet POS tags. This simplification could result in a reduction in accuracy with only Nouns, Verbs, Adverbs, and Adjectives as classes for tagging and if no mapping was available words were defaulted to Nouns. \n",
    "- Words were then lemmatised to create denser vectors making the processing and modelling less computationally intesive, given the relatively large dataset. \n",
    "- Further processing of the tokenised / lemmatised text was then undertaken for the different representations used by the different models, with this processing detailed below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bfd5a727276dd53f136df6d1d262fe6",
     "grade": false,
     "grade_id": "cell-0a65e991a54b21c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 3\n",
    "Description and commentary on the machine learning architectures used, including a description and justification of the text representation method(s) used. (**7%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03960b9d6fae49a8bbd6547d5c67b9fc",
     "grade": true,
     "grade_id": "cell-6c64da91adfef770",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### Machine Learning Models\n",
    "\n",
    "#### Naive Bayes \n",
    "\n",
    "\n",
    "\n",
    "#### k Nearest Neighbours \n",
    "\n",
    "\n",
    "\n",
    "#### Convolutional Neural Network \n",
    "\n",
    "\n",
    "\n",
    "#### Long Short-Term Memory Model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes \n",
    "\n",
    "- Term Frequency-Inverse Document Freuency (TF-IDF) vector word embedding was used due to its compatibility with Naive Bayes, with each document represented as a vector and each vector element representing a specific words TF-IDF score. TF-IDF weights words based on how often they appear across all documents allowing the Naive Bayes model to focus on terms which should be more impactful in predicting the sentiment of a review and reducing the impact of common words which should be less impactful. \n",
    "- Multinomial Naive Bayes was chosen given the 5 classes for prediction. \n",
    "- Laplace Smoothing was used to address the problem of zero probabilities and 5-fold cross-validation was used to choose the best alpha value, using accuracy as the performance metric compared. This helped prevent the model from predicting almost exclusively scores of 5 due to the class imbalance in the dataset. \n",
    "\n",
    "#### k Nearest Neighbours \n",
    "\n",
    "- Word2Vec Continuous Bag of Words word embedding was used to create 300 dimensional dense vector representations of each word and then these were used to create dense vector representations of each review (document). Each word was transformed into a 300 length vector representation, 300 was chosen as a trade-off between capturing as much information as possible about each word and the added computational complexity of higher dimensional vectors. The context window was chosen as 5 to capture the context of the 5 words either side of any specific word to learn from. The dense vector representations for the words in a review were then averaged to get a dense document representation (300 dimensional vector) to capture the average sentiment in each review. A single document representation was chosen given that it reduces the computational complexity when using k Nearest Neighbours relative to sparse vector representation or dense vector representation per word formats. \n",
    "- 5-fold cross-validation was used to choose the best value of k (from 1, 3, 5, 7), using accuracy as the performance metric compared. A k value of 7 was determined to have the highest average accuracy in cross-validation, see Figure 2. \n",
    "\n",
    "__Figure 2.__\n",
    "![Figure 2.](Figure_2.png)\n",
    "\n",
    "#### Convolutional Neural Network \n",
    "\n",
    "- Word2Vec Continuous Bag of Words word embedding was used to created 50 dimensional dense vector representations of each word and then these were used to create a matrix of dense vector word representations for each review (50 by 50). 50 diminsions was chosen to reduce the space complexity of the Word2Vec embeddings and to reduce the time complexity for model training. The distribution of words per review was analysed and it was determined that 50 words would capture all the words in just under 75% or all reviews, see Figure 3. Matrices for reviews with less than 50 words were padded with zeros and reviews with more than 50 words were truncated to 50 to ensure that the matrix representations for all reviews had the same dimensions. This was determined to be a good trade-off between the amount of information able to be captured in each review matrix and the increased space and time complexity of larger matrices. \n",
    "\n",
    "__Figure 3.__\n",
    "![Figure 3.](Figure_3.png)\n",
    "\n",
    "- The model arhcitecture used a 50 by 50 input shape feeding into a 1-dimensional convolutional layer with a filter size of 128, kernal size of 5 and ReLU activation function. The layer is designed to capture local patterns in the input with a 5 word context window and the 128 node filter size was chosen as a trade-off between being able to capture complex patterns in the data and computational complexity. A 1-dimensional max pooling layer follows to try and abstract the features extracted by the previous layer and prevent overfitting. A 1-dimensional convolutional layer identical to the first follows to try and further refine the features extracted from the input. A 1-dimensional global max pooling layer follows to reduce the dimensionality before connecting to the following dense layer which interprets the feature extracted and pooled by previous layers and contains 128 nodes and uses the ReLu activation function. All ReLU activation functions used are to introduce non-linearity to the model to allow it to capture non-linear relationships and ReLU is more computationally efficient than other non-linear options. The output layer is a dense layer with 5 nodes corresponding to the number of classes with a softmax activation function used to output the probability distribution over the 5 classes. \n",
    "- The loss function used was sparse categorical cross entropy due to the multi-class nature of the classification problem and the mutually expclusive classes. \n",
    "- The Adam optimiser was used as it is conventional and computationally efficient. \n",
    "- A 70/30 train/validation split was used for model training with a stoping condition on no accuracy improvement for 3 epochs to prevent unneccassary computation. \n",
    "- Accuracy was chosen as the performance metric for model training, however given the class imbalance present repeating the analysis using F1-Score might be worthwhile. \n",
    "\n",
    "#### Long Short-Term Memory Model \n",
    "\n",
    "- The same Word2Vec Continuous Bag of Words 50 by 50 matrices of dense vector word representations for reviews was used as described in the Convolutional Neural Network section for the same reasons described. \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "874f5d8565ae3e5a4cb52d837e4beceb",
     "grade": false,
     "grade_id": "cell-7112118f421c6a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 4\n",
    "Detailed performance evaluation of the trained machine learning models in terms of the computed performance metrics. (**5%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "071a2e19285688d52725adc2063d2044",
     "grade": true,
     "grade_id": "cell-201e49e468eaa417",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "#### Naive Bayes \n",
    "\n",
    "__Figure 6.__\n",
    "![Figure 6.](Figure_6.png)\n",
    "\n",
    "__Table 1.__\n",
    "\n",
    "| Performance Metric | Score |\n",
    "|----------|----------|\n",
    "| Accuracy: | 0.68 |\n",
    "| F1-Score: | 0.31 |\n",
    "| Precision: | 0.49 |\n",
    "| Recall: | 0.30 |\n",
    "\n",
    "Note: Macro-averaging used for F1-Score, Precision, and recall. \n",
    "\n",
    "Naive Bayes had an overall accuracy of 0.68, however this is due to the model primarily predicting Scores of 5 and the test dataset having majority 5 Scores. The model predicts 5 the majority of the time despite the true class and this is reflected in the low recall score \n",
    "\n",
    "#### k Nearest Neighbours \n",
    "\n",
    "__Figure 7.__\n",
    "![Figure 7.](Figure_7.png)\n",
    "\n",
    "__Table 2.__\n",
    "\n",
    "| Performance Metric | Score |\n",
    "|----------|----------|\n",
    "| Accuracy: | 0.66 |\n",
    "| F1-Score: | 0.37 |\n",
    "| Precision: | 0.40 |\n",
    "| Recall: | 0.36 |\n",
    "\n",
    "Note: Macro-averaging used for F1-Score, Precision, and recall. \n",
    "\n",
    "#### Convolutional Neural Network \n",
    "\n",
    "__Figure 8.__\n",
    "![Figure 8.](Figure_8.png)\n",
    "\n",
    "__Table 3.__\n",
    "\n",
    "| Performance Metric | Score |\n",
    "|----------|----------|\n",
    "| Accuracy: | 0.71 |\n",
    "| F1-Score: | 0.41 |\n",
    "| Precision: | 0.49 |\n",
    "| Recall: | 0.41 |\n",
    "\n",
    "Note: Macro-averaging used for F1-Score, Precision, and recall. \n",
    "\n",
    "#### Long Short-Term Memory Model \n",
    "\n",
    "__Figure 9.__\n",
    "![Figure 9.](Figure_9.png)\n",
    "\n",
    "__Table 1.__\n",
    "\n",
    "| Performance Metric | Score |\n",
    "|----------|----------|\n",
    "| Accuracy: | 0.74 |\n",
    "| F1-Score: | 0.50 |\n",
    "| Precision: | 0.55 |\n",
    "| Recall: | 0.49 |\n",
    "\n",
    "Note: Macro-averaging used for F1-Score, Precision, and recall. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac8dc11dd7f998b7d3d5c0e904c08c5f",
     "grade": false,
     "grade_id": "cell-5e6e5b8b57811a63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 5\n",
    "Critical discussion on the achieved results, including potential limitations and usage instructions/suggestions. (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27dd1c5197d66c3081a133456110abb0",
     "grade": true,
     "grade_id": "cell-11c60b80d50f1d27",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Potential improvements:\n",
    "\n",
    "- Using a class balanced trianing set and testing on the test set \n",
    "- Using F1-Score for model selection?\n",
    "- Increasing the number of nodes per layer in NNs \n",
    "- Including negation stop words to see if it increases performance "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
