{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Alasdair Breasley\"\n",
    "CIS_USERNAME = \"fmcv76\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2ed8244d1822167b9619a27c5056a2d",
     "grade": false,
     "grade_id": "cell-c772e32fbd55cccd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# COMP42415 Text Mining and Language Analytics\n",
    "## Coursework 2023-24\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "- <ins>**DO NOT RENAME THIS JUPYTER NOTEBOOK !!!**</ins>\n",
    "- Please write the answers for each question in the respective cell. \n",
    "- You can add more cells if needed.\n",
    "- If needed, you can upload additional files, e.g. pre-trained word embeddings, in the coursework's directory\n",
    "- You can safely remove the `raise NotImplementedError()` line from each code cell.\n",
    "- You can find information about markdown syntax from [here](https://www.markdownguide.org/basic-syntax/#emphasis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-030e957d0f52>:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import required packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "068e2a188a6a3db5c142be9d8afbb053",
     "grade": false,
     "grade_id": "cell-7f0204ddaabf431f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 1\n",
    "Prepare the dataset by applying any pre-processing or cleaning steps that you consider as necessary. Then, split the dataset into a training set containing 70% of the samples and a test set containing 30% of the samples. Follow an appropriate strategy for the split. You must use these training/test sets for all the models in this coursework. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d8184a650c6efb613adc101bb08baf9",
     "grade": true,
     "grade_id": "cell-1ec6ac90f0506a35",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score                                           Summary  \\\n",
      "0      5                                      three cheese   \n",
      "1      5                        Coffee  ***UPDATE*** added   \n",
      "2      5                    Delicious cocoa for grown ups!   \n",
      "3      5  Really Good Fresh Murray's Sugar-Free Shortbread   \n",
      "4      3                                         OK Coffee   \n",
      "\n",
      "                                                Text  \n",
      "0  really good three cheese potatoes great with h...  \n",
      "1  I love coffee, and a particular fantasy of min...  \n",
      "2  This is not sugary sweet hot chocolate, nor is...  \n",
      "3  These cookies arrived quickly and are in great...  \n",
      "4  This is decent coffee. Nothing special. It is ...   \n",
      "\n",
      "(540031, 3) \n",
      "\n",
      "Score       int64\n",
      "Summary    object\n",
      "Text       object\n",
      "dtype: object \n",
      "\n",
      "[5 3 1 4 2] \n",
      "\n",
      "162009 \n",
      "\n",
      "(378022, 3) \n",
      "\n",
      "99031 \n",
      "\n",
      "0 \n",
      "\n",
      "377114 \n",
      "\n",
      "0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import food reviews data \n",
    "food_reviews_data = pd.read_csv(\"food_reviews.csv\")\n",
    "\n",
    "# Check dataframe head \n",
    "print(food_reviews_data.head(5), \"\\n\")\n",
    "\n",
    "# Check dataframe shape \n",
    "print(food_reviews_data.shape, \"\\n\")\n",
    "\n",
    "# Check data types \n",
    "print(food_reviews_data.dtypes, \"\\n\")\n",
    "\n",
    "# Check uniqueness of Score column \n",
    "print(food_reviews_data[\"Score\"].unique(), \"\\n\")\n",
    "\n",
    "# Check for duplicate rows \n",
    "print(food_reviews_data[food_reviews_data.duplicated()].shape[0], \"\\n\")\n",
    "\n",
    "# Remove duplicate rows \n",
    "food_reviews_data = food_reviews_data.drop_duplicates()\n",
    "\n",
    "# Recheck dataframe shape \n",
    "print(food_reviews_data.shape, \"\\n\")\n",
    "\n",
    "# Check how many rows contain html tags \n",
    "print(food_reviews_data[\"Text\"].str.contains(r\"<.+?>\").sum(), \"\\n\")\n",
    "\n",
    "# Replace html tags with \" \", \" \" as opposed to \"\" to not join words unintentionally \n",
    "food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"<.+?>\", \" \", regex = True)\n",
    "\n",
    "# Recheck how many rows contain html tags \n",
    "print(food_reviews_data[\"Text\"].str.contains(r\"<.+?>\").sum(), \"\\n\")\n",
    "\n",
    "# Transform Text column to all lowercase \n",
    "food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.lower()\n",
    "\n",
    "# Check how many rows include punctuation \n",
    "print(food_reviews_data[\"Text\"].str.contains(r\"[^\\w\\s]\").sum(), \"\\n\")\n",
    "\n",
    "# Remove punctuation \n",
    "food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[^\\w\\s]\", \" \", regex = True)\n",
    "\n",
    "# Recheck how many rows include punctuation \n",
    "print(food_reviews_data[\"Text\"].str.contains(r\"[^\\w\\s]\").sum(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily reduce dataframe size for developement \n",
    "food_reviews_data = food_reviews_data[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wordnet(penn_pos_tag):\n",
    "    \"\"\"Function to convert Penn Treeback POS tags to WordNet\"\"\"\n",
    "    \n",
    "    tag_dictionary = {\"NN\":\"n\", \"JJ\":\"a\",\"VB\":\"v\", \"RB\":\"r\"}\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # If the first two characters of the Penn Treebank POS tag are in the tag_dictionary \n",
    "        return tag_dictionary[penn_pos_tag[:2]]\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return \"n\" # Default to Noun if no mapping avalable.\n",
    "    \n",
    "\n",
    "# Get list of English stop words \n",
    "stopwords_english = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords_and_lemmatise(text):\n",
    "    \"\"\"Function to tokenise a string, remove stop words, and concatinate back together.\"\"\"\n",
    "    \n",
    "    # Tokenise text into words \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words \n",
    "    words_filtered = [word for word in words if word not in stopwords_english]\n",
    "    \n",
    "    # TODO: Update to use full conversion table as opposed to simplified version \n",
    "    \n",
    "    # Apply POS tagging \n",
    "    words_pos_tagged = pos_tag(words_filtered)\n",
    "    \n",
    "    # Create a WordNetLemmatizer object \n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    # Define empty lemmas list \n",
    "    lemmas = []\n",
    "    \n",
    "    # Loop through words in sentence and lemmatise \n",
    "    for word, tag in words_pos_tagged:\n",
    "    \n",
    "        lemmas.append(wnl.lemmatize(word, pos = penn_to_wordnet(tag)))\n",
    "    \n",
    "    # Concatinate remaining words back into a string \n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "\n",
    "# Remove stop words from Text column \n",
    "food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].apply(remove_stopwords_and_lemmatise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cee84be8ff5d30b3cc777f43b92b5b69",
     "grade": false,
     "grade_id": "cell-b691a7bc111d2ca5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 2\n",
    "Implement a Naïve Bayes model for predicting the rating of a food review. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**5%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "638739c81d3d084fbcc8233bbecb6b02",
     "grade": true,
     "grade_id": "cell-c7228a828210126a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a8672a0a32389c7076c73d1de3acfb1",
     "grade": false,
     "grade_id": "cell-bd3fe708de79e951",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 3\n",
    "Implement a k-Nearest Neighbours model for predicting the rating of a food review. Train your model on the training set and test it on the test set. Use an appropriate text representation. You must select the best k by examining the performance of the model for $k \\in \\{1,3,5,7\\}$, using an appropriate cross-validation approach. Create a plot for k vs. classification performance to justify your choice. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7c5809dc4f4de2b111845abdcf40ddf",
     "grade": true,
     "grade_id": "cell-e566d393c7fac970",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43ad334a0b661041421fbde0c35614c1",
     "grade": false,
     "grade_id": "cell-ceb568d7b9979383",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 4\n",
    "Implement a Convolutional Neural Network (CNN) model for predicting the rating of a food review. The model must have at least two convolutional layers. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**13%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc79d3616790883ed0539f3416cb92ad",
     "grade": true,
     "grade_id": "cell-8062f67e02d4c61f",
     "locked": false,
     "points": 13,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74843fe33a4f86a21469871aac52bb90",
     "grade": false,
     "grade_id": "cell-a985e9ca1140281d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 5\n",
    "Implement a Recurrent Neural Network (RNN) or a Long Short-Term Memory (LSTM) model for predicting the rating of a food review. The model must have at least two RNN/LSTM layers. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**12%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb7179dcc099d3d51db8e0d4d4c53c7b",
     "grade": true,
     "grade_id": "cell-76f081948cba4b02",
     "locked": false,
     "points": 12,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5e477712b6bad9901556381dd829392",
     "grade": false,
     "grade_id": "cell-9f3d1c8c43462384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 6\n",
    "Compute the confusion matrix, accuracy, F1-score, precision and recall for each model. (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5080f7d517214809afe68eee9318b427",
     "grade": true,
     "grade_id": "cell-b3a9e53040d493c1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9def807c7734179b60c1d5121bbbd436",
     "grade": false,
     "grade_id": "cell-290a6e3bf464e305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 7\n",
    "Store the **four** trained models in files and implement a function `predict_food_review(text, model)` that given a <ins>text string</ins> (“`text`”) and model <ins>filename</ins> (“`model`”), it will load the pre-trained model, and predict the food review rating of the input text. The function should be able to work without requiring to rerun all or part of your code. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03a2117734166d6e91043d88d5c5ef8a",
     "grade": true,
     "grade_id": "cell-f384d017d7d6ac75",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66fe20bf6b18e122ab5eb3a8110ee13b",
     "grade": false,
     "grade_id": "cell-3632d0c81d039058",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 1\n",
    "Critical discussion about the dataset (suitability, problems, class balance, etc.). (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c04a7d6b4dc1614cce18ae7dc9b59ee0",
     "grade": true,
     "grade_id": "cell-723b0c0e08ba0f30",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e16e80cbdb327b4bd8b3dc8644c93953",
     "grade": false,
     "grade_id": "cell-cf6f3bf73d0b219c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 2\n",
    "Description and justification of the data preparation step(s) used. (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d827d373523a1ebd5f7adf108d5fc5e",
     "grade": true,
     "grade_id": "cell-ff3a7a6577a764fb",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bfd5a727276dd53f136df6d1d262fe6",
     "grade": false,
     "grade_id": "cell-0a65e991a54b21c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 3\n",
    "Description and commentary on the machine learning architectures used, including a description and justification of the text representation method(s) used. (**7%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03960b9d6fae49a8bbd6547d5c67b9fc",
     "grade": true,
     "grade_id": "cell-6c64da91adfef770",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "874f5d8565ae3e5a4cb52d837e4beceb",
     "grade": false,
     "grade_id": "cell-7112118f421c6a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 4\n",
    "Detailed performance evaluation of the trained machine learning models in terms of the computed performance metrics. (**5%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "071a2e19285688d52725adc2063d2044",
     "grade": true,
     "grade_id": "cell-201e49e468eaa417",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac8dc11dd7f998b7d3d5c0e904c08c5f",
     "grade": false,
     "grade_id": "cell-5e6e5b8b57811a63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 5\n",
    "Critical discussion on the achieved results, including potential limitations and usage instructions/suggestions. (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27dd1c5197d66c3081a133456110abb0",
     "grade": true,
     "grade_id": "cell-11c60b80d50f1d27",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
