{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Alasdair Breasley\"\n",
    "CIS_USERNAME = \"fmcv76\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2ed8244d1822167b9619a27c5056a2d",
     "grade": false,
     "grade_id": "cell-c772e32fbd55cccd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# COMP42415 Text Mining and Language Analytics\n",
    "## Coursework 2023-24\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "- <ins>**DO NOT RENAME THIS JUPYTER NOTEBOOK !!!**</ins>\n",
    "- Please write the answers for each question in the respective cell. \n",
    "- You can add more cells if needed.\n",
    "- If needed, you can upload additional files, e.g. pre-trained word embeddings, in the coursework's directory\n",
    "- You can safely remove the `raise NotImplementedError()` line from each code cell.\n",
    "- You can find information about markdown syntax from [here](https://www.markdownguide.org/basic-syntax/#emphasis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-1935d981abf1>:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home3/fmcv76/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import required packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "from nltk import pos_tag\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score,precision_score, recall_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set() # Use seaborn plotting style\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import ast\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls \n",
    "class_balance_sampling = False\n",
    "subset_data = False\n",
    "subset_size = 50000 # Total size of the subset used for training and testing \n",
    "\n",
    "load_preprocessed_data = True\n",
    "load_precalculated_w2v_embeddings = True\n",
    "run_kNN = False\n",
    "load_NB = False\n",
    "load_kNN = False\n",
    "load_CNN = False\n",
    "load_LSTM = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "068e2a188a6a3db5c142be9d8afbb053",
     "grade": false,
     "grade_id": "cell-7f0204ddaabf431f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 1\n",
    "Prepare the dataset by applying any pre-processing or cleaning steps that you consider as necessary. Then, split the dataset into a training set containing 70% of the samples and a test set containing 30% of the samples. Follow an appropriate strategy for the split. You must use these training/test sets for all the models in this coursework. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d8184a650c6efb613adc101bb08baf9",
     "grade": true,
     "grade_id": "cell-1ec6ac90f0506a35",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    # Import food reviews data \n",
    "    food_reviews_data = pd.read_csv(\"food_reviews.csv\")\n",
    "    \n",
    "    # Check dataframe head \n",
    "    print(food_reviews_data.head(5), \"\\n\")\n",
    "    \n",
    "    # Check dataframe shape \n",
    "    print(food_reviews_data.shape, \"\\n\")\n",
    "    \n",
    "    # Check data types \n",
    "    print(food_reviews_data.dtypes, \"\\n\")\n",
    "    \n",
    "    # Check uniqueness of Score column \n",
    "    print(food_reviews_data[\"Score\"].unique(), \"\\n\")\n",
    "    \n",
    "    # Check for duplicate rows \n",
    "    print(food_reviews_data[food_reviews_data.duplicated()].shape[0], \"\\n\")\n",
    "    \n",
    "    # Remove duplicate rows \n",
    "    food_reviews_data = food_reviews_data.drop_duplicates()\n",
    "    \n",
    "    # Recheck dataframe shape \n",
    "    print(food_reviews_data.shape, \"\\n\")\n",
    "    \n",
    "    # Concatinate Summary column with Text column to capture all available information \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Summary\"].astype(str) + \" \" + food_reviews_data[\"Text\"].astype(str)\n",
    "    \n",
    "    # TODO: Decide if adding both columns together makes sense \n",
    "    \n",
    "    # Check how many rows contain html tags \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"<.+?>\").sum(), \"\\n\")\n",
    "    \n",
    "    # Replace html tags with \" \", \" \" as opposed to \"\" to not join words unintentionally \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"<.+?>\", \" \", regex = True)\n",
    "    \n",
    "    # Recheck how many rows contain html tags \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"<.+?>\").sum(), \"\\n\")\n",
    "    \n",
    "    # Transform Text column to all lowercase \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.lower()\n",
    "    \n",
    "    # Check how many rows include happy or sad text emojis \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[:][)]|[:][(]|[)][:]|[(][:]\").sum(), \"\\n\")\n",
    "    \n",
    "    # Replace happy emojis with \" happy \" \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[:][)]|[(][:]\", \" happy \", regex = True)\n",
    "    \n",
    "    # Replace sad emojis with \" sad \" \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[:][(]|[)][:]\", \" sad \", regex = True)\n",
    "    \n",
    "    # Recheck how many rows include happy or sad text emojis \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[:][)]|[:][(]|[)][:]|[(][:]\").sum(), \"\\n\")\n",
    "    \n",
    "    # Check how many rows include punctuation \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[^\\w\\s]\").sum(), \"\\n\")\n",
    "    \n",
    "    # TODO: Decide if \"'\" should be removed at this point or if some of the later steps can handle don't etc. \n",
    "    \n",
    "    # Remove punctuation \n",
    "    food_reviews_data[\"Text\"] = food_reviews_data[\"Text\"].str.replace(r\"[^\\w\\s]\", \" \", regex = True)\n",
    "    \n",
    "    # Recheck how many rows include punctuation \n",
    "    print(food_reviews_data[\"Text\"].str.contains(r\"[^\\w\\s]\").sum(), \"\\n\")\n",
    "    \n",
    "    # Check for class imbalance \n",
    "    print(food_reviews_data[\"Score\"].value_counts(), \"\\n\")\n",
    "    \n",
    "    # There is class imbalance present \n",
    "    \n",
    "    # Check dataframe head \n",
    "    print(food_reviews_data.head(5), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    if (subset_data != True):\n",
    "        \n",
    "        subset_size = len(food_reviews_data)\n",
    "        \n",
    "        \n",
    "    if (class_balance_sampling != True):\n",
    "        \n",
    "        # Temporarily reduce dataframe size for developement \n",
    "        food_reviews_data = food_reviews_data[0:subset_size]\n",
    "        \n",
    "        \n",
    "    # Check for class imbalance \n",
    "    print(food_reviews_data[\"Score\"].value_counts())\n",
    "    \n",
    "    # There is class imbalance present \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    def penn_to_wordnet(penn_pos_tag):\n",
    "        \"\"\"Function to convert Penn Treeback POS tags to WordNet\"\"\"\n",
    "        \n",
    "        tag_dictionary = {\"NN\":\"n\", \"JJ\":\"a\",\"VB\":\"v\", \"RB\":\"r\"}\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # If the first two characters of the Penn Treebank POS tag are in the tag_dictionary \n",
    "            return tag_dictionary[penn_pos_tag[:2]]\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            return \"n\" # Default to Noun if no mapping avalable.\n",
    "        \n",
    "    \n",
    "    # Get list of English stop words \n",
    "    stopwords_english = stopwords.words(\"english\")\n",
    "    \n",
    "    def remove_stopwords_and_lemmatise(text):\n",
    "        \"\"\"Function to tokenise a string, remove stop words, lemmatise, and concatinate back together.\"\"\"\n",
    "        \n",
    "        # Tokenise text into words \n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # Remove stop words \n",
    "        words_filtered = [word for word in words if word not in stopwords_english]\n",
    "        \n",
    "        # TODO: Update to use full conversion table as opposed to simplified version \n",
    "        \n",
    "        # Apply POS tagging \n",
    "        words_pos_tagged = pos_tag(words_filtered)\n",
    "        \n",
    "        # Create a WordNetLemmatizer object \n",
    "        wnl = WordNetLemmatizer()\n",
    "        \n",
    "        # Define empty lemmas list \n",
    "        lemmas = []\n",
    "        \n",
    "        # Loop through words in sentence and lemmatise \n",
    "        for word, tag in words_pos_tagged:\n",
    "        \n",
    "            lemmas.append(wnl.lemmatize(word, pos = penn_to_wordnet(tag)))\n",
    "        \n",
    "        # Concatinate remaining words back into a string \n",
    "        return lemmas\n",
    "    \n",
    "    \n",
    "    #if (class_balance_sampling != True):\n",
    "        \n",
    "        # Remove stop words from Text column \n",
    "        #food_reviews_data_tokenised = food_reviews_data[\"Text\"].apply(remove_stopwords_and_lemmatise)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    if (class_balance_sampling != True):\n",
    "        \n",
    "        # Split data into training (70%) and test (30%) splits \n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(food_reviews_data[\"Text\"], food_reviews_data[\"Score\"], \n",
    "                                                                            test_size = 0.3, random_state = 123, \n",
    "                                                                            stratify = food_reviews_data[\"Score\"])\n",
    "        \n",
    "        # TODO: Decide if it should be stratified random sampling or random sampling \n",
    "        \n",
    "        # Remove stop words from train data and lemmatise \n",
    "        train_data_tokenised = train_data.apply(remove_stopwords_and_lemmatise)\n",
    "        \n",
    "        # Join lists of lemmas to string (need both ways) \n",
    "        train_data = [\" \".join(lemmas) for lemmas in train_data_tokenised]\n",
    "        \n",
    "        # Remove stop words from test data and lemmatise \n",
    "        test_data_tokenised = test_data.apply(remove_stopwords_and_lemmatise)\n",
    "        \n",
    "        # Join lists of lemmas to string (need both ways) \n",
    "        test_data = [\" \".join(lemmas) for lemmas in test_data_tokenised]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    # Save tokenised train data to csv \n",
    "    train_data_tokenised_csv = pd.Series(train_data_tokenised)\n",
    "    train_data_tokenised_csv.to_csv(\"train_data_tokenised.csv\")\n",
    "    \n",
    "    # Save train data to csv \n",
    "    train_data_csv = pd.DataFrame({\"Text\" : train_data, \n",
    "                                   \"Score\" : train_labels})\n",
    "    train_data_csv.to_csv(\"train_data.csv\")\n",
    "    \n",
    "    # Save tokenised test data to csv \n",
    "    test_data_tokenised_csv = pd.Series(test_data_tokenised)\n",
    "    test_data_tokenised_csv.to_csv(\"test_data_tokenised.csv\")\n",
    "    \n",
    "    # Save test data to csv \n",
    "    test_data_csv = pd.DataFrame({\"Text\" : test_data, \n",
    "                                  \"Score\" : test_labels})\n",
    "    test_data_csv.to_csv(\"test_data.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_preprocessed_data == True):\n",
    "    \n",
    "    # Load preprocessed tokenised train data \n",
    "    train_data_tokenised = pd.read_csv(\"train_data_tokenised.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    train_data_tokenised = [ast.literal_eval(text) for text in train_data_tokenised]\n",
    "    \n",
    "    # Load preprocessed train data \n",
    "    train_data = pd.read_csv(\"train_data.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    \n",
    "    # Load train labels \n",
    "    train_labels = pd.read_csv(\"train_data.csv\", index_col = 0)[\"Score\"].tolist()\n",
    "    \n",
    "    # Load preprocessed tokenised test data \n",
    "    test_data_tokenised = pd.read_csv(\"test_data_tokenised.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    test_data_tokenised = [ast.literal_eval(text) for text in test_data_tokenised]\n",
    "    \n",
    "    # Load preprocessed test data \n",
    "    test_data = pd.read_csv(\"test_data.csv\", index_col = 0)[\"Text\"].tolist()\n",
    "    \n",
    "    # Load train labels \n",
    "    test_labels = pd.read_csv(\"test_data.csv\", index_col = 0)[\"Score\"].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_preprocessed_data != True):\n",
    "    \n",
    "    if (class_balance_sampling == True):\n",
    "        \n",
    "        # Define the number of samples for the test set \n",
    "        n_samples_test = round(subset_size * 0.3)\n",
    "        \n",
    "        total_samples = food_reviews_data.shape[0]\n",
    "        \n",
    "        test_size_proportion = n_samples_test / total_samples\n",
    "        \n",
    "        train_data_preclassbalanced, test_data = train_test_split(food_reviews_data, test_size = test_size_proportion, \n",
    "                                                                  random_state = 123, stratify = food_reviews_data[\"Score\"])\n",
    "    \n",
    "        test_data = test_data.reset_index(drop = True)\n",
    "        \n",
    "        test_data[\"Text\"] = test_data[\"Text\"].apply(remove_stopwords_and_lemmatise)\n",
    "        \n",
    "        # Check for class imbalance \n",
    "        print(test_data[\"Score\"].value_counts(), \"\\n\")\n",
    "        \n",
    "        # Check for class imbalance \n",
    "        print(train_data_preclassbalanced[\"Score\"].value_counts(), \"\\n\")\n",
    "        \n",
    "        n_samples_per_class = round(n_samples_test * (7 / 3) / 5)\n",
    "        \n",
    "        # TODO: Return error if not enough of any class present \n",
    "        \n",
    "        classes = train_data_preclassbalanced[\"Score\"].unique()\n",
    "        \n",
    "        sampled_class_dataframes = []\n",
    "        \n",
    "        for class_ in classes:\n",
    "            \n",
    "            class_dataframe = train_data_preclassbalanced[train_data_preclassbalanced[\"Score\"] == class_]\n",
    "            \n",
    "            sampled_class_dataframe = class_dataframe.sample(n = n_samples_per_class, random_state = 123)\n",
    "            \n",
    "            sampled_class_dataframes.append(sampled_class_dataframe)\n",
    "        \n",
    "        \n",
    "        train_data = pd.concat(sampled_class_dataframes).reset_index(drop = True)\n",
    "        \n",
    "        train_data[\"Text\"] = train_data[\"Text\"].apply(remove_stopwords_and_lemmatise)\n",
    "        \n",
    "        # Check for class imbalance \n",
    "        print(train_data[\"Score\"].value_counts(), \"\\n\")\n",
    "        \n",
    "        test_labels = test_data[\"Score\"]\n",
    "        \n",
    "        test_data = test_data[\"Text\"]\n",
    "        \n",
    "        train_labels = train_data[\"Score\"]\n",
    "        \n",
    "        train_data = train_data[\"Text\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cee84be8ff5d30b3cc777f43b92b5b69",
     "grade": false,
     "grade_id": "cell-b691a7bc111d2ca5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 2\n",
    "Implement a Na√Øve Bayes model for predicting the rating of a food review. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**5%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "638739c81d3d084fbcc8233bbecb6b02",
     "grade": true,
     "grade_id": "cell-c7228a828210126a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (load_NB != True):\n",
    "    \n",
    "    # Naive Bayes model - input is converted to TF-IDF vectors and then Multinomial Naive Bayes is used \n",
    "    nb_model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "    \n",
    "    # Train model \n",
    "    nb_model.fit(train_data, train_labels)\n",
    "    \n",
    "    # Save model \n",
    "    nb_model_filename = \"nb_model.pkl\"\n",
    "    \n",
    "    with open(nb_model_filename, \"wb\") as file:\n",
    "        \n",
    "        pickle.dump(nb_model, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_NB == True):\n",
    "    \n",
    "    with open(\"nb_model.pkl\", \"rb\") as file:\n",
    "        \n",
    "        nb_model = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model \n",
    "nb_predictions = nb_model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.644184\n",
      "F1-score:\t0.185809\n",
      "Precision:\t0.397136\n",
      "Recall:\t\t0.215895\n",
      "\n",
      "Classification performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.08      0.14     10477\n",
      "           2       0.00      0.00      0.00      5976\n",
      "           3       0.14      0.00      0.00      8574\n",
      "           4       0.33      0.00      0.00     16139\n",
      "           5       0.64      1.00      0.78     72241\n",
      "\n",
      "    accuracy                           0.64    113407\n",
      "   macro avg       0.40      0.22      0.19    113407\n",
      "weighted avg       0.55      0.64      0.51    113407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "matrix = confusion_matrix(test_labels, nb_predictions)\n",
    "sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "           xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and print classification performance metrics\n",
    "print(\"Accuracy:\\t%f\" % accuracy_score(test_labels, nb_predictions))\n",
    "print(\"F1-score:\\t%f\" % f1_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"Precision:\\t%f\" % precision_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"Recall:\\t\\t%f\" % recall_score(test_labels, nb_predictions, average = \"macro\"))\n",
    "print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a8672a0a32389c7076c73d1de3acfb1",
     "grade": false,
     "grade_id": "cell-bd3fe708de79e951",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 3\n",
    "Implement a k-Nearest Neighbours model for predicting the rating of a food review. Train your model on the training set and test it on the test set. Use an appropriate text representation. You must select the best k by examining the performance of the model for $k \\in \\{1,3,5,7\\}$, using an appropriate cross-validation approach. Create a plot for k vs. classification performance to justify your choice. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    if (load_precalculated_w2v_embeddings != True):\n",
    "        \n",
    "        # Train word2vec word embedding model using train data to create denser vectors  \n",
    "        w2v_word_embeddings = gensim.models.Word2Vec(train_data_tokenised, vector_size = 300, window = 5, \n",
    "                                                     min_count = 1, sg = 0, seed = 123)\n",
    "        \n",
    "        # Save word2vec word embeddings \n",
    "        w2v_word_embeddings.save(\"w2v_word_embeddings.model\")\n",
    "        \n",
    "# TODO: Explain why vector_size and window chosen \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    if (load_precalculated_w2v_embeddings == True):\n",
    "        \n",
    "        # Load word2vec word embeddings \n",
    "        w2v_word_embeddings = Word2Vec.load(\"w2v_word_embeddings.model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    def text_to_vector(text, w2v_word_embeddings):\n",
    "        \"\"\"Function to trasform text (a review) in the form of a list of word embeddings into a single \n",
    "        vector representation which is the average vector representation of the embedded words in the review.\"\"\"\n",
    "        \n",
    "        vector = sum(w2v_word_embeddings.wv[word] for word in text if word in w2v_word_embeddings.wv) / len(text)\n",
    "        \n",
    "        return vector\n",
    "\n",
    "\n",
    "if (run_kNN):\n",
    "    \n",
    "    # Vectorise train data into dense vector representations \n",
    "    train_data_w2v_vectorized = [text_to_vector(text, w2v_word_embeddings) for text in train_data_tokenised]\n",
    "    \n",
    "    # Vectorise test data into dense vector representations \n",
    "    test_data_w2v_vectorized = [text_to_vector(text, w2v_word_embeddings) for text in test_data_tokenised]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7c5809dc4f4de2b111845abdcf40ddf",
     "grade": true,
     "grade_id": "cell-e566d393c7fac970",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    # Values of k to test \n",
    "    k_values = [1, 3, 5, 7]\n",
    "    \n",
    "    mean_accuracies = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        \n",
    "        knn_model = KNeighborsClassifier(n_neighbors = k)\n",
    "        \n",
    "        scores = cross_val_score(knn_model, train_data_w2v_vectorized, train_labels, cv = 5, scoring = \"accuracy\")\n",
    "        \n",
    "        # TODO: Explain why Accuracy vs F1-Score - If doing class balanced sampling then doesn't matter, \n",
    "        # if not then F1-Score makes most sense because of class imbalance \n",
    "        \n",
    "        mean_accuracy = scores.mean()\n",
    "        \n",
    "        mean_accuracies.append(mean_accuracy)\n",
    "        \n",
    "        \n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(k_values, mean_accuracies, marker = \"o\", linestyle = \"-\", color = \"b\")\n",
    "    plt.title(\"kNN Model Performance by Number of Neighbors\")\n",
    "    plt.xlabel(\"Number of Neighbors (k)\")\n",
    "    plt.ylabel(\"Mean Accuracy\")\n",
    "    plt.xticks(k_values)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    if (load_kNN != True):\n",
    "        \n",
    "        # k Nearest Neighbour model - input is converted to TF-IDF vectors and then kNN is used \n",
    "        # The k value which produced the hgihest accuracy from cross-validation on the train/validation set is used \n",
    "        knn_model = KNeighborsClassifier(n_neighbors = k_values[mean_accuracies.index(max(mean_accuracies))])\n",
    "        \n",
    "        # Train model \n",
    "        knn_model.fit(train_data_w2v_vectorized, train_labels)\n",
    "        \n",
    "        # Save model \n",
    "        knn_model_filename = \"knn_model.pkl\"\n",
    "        \n",
    "        with open(knn_model_filename, \"wb\") as file:\n",
    "            \n",
    "            pickle.dump(knn_model, file)\n",
    "        \n",
    "    if (load_kNN == true):\n",
    "        \n",
    "        with open(\"knn_model.pkl\", \"rb\") as file:\n",
    "            \n",
    "            knn_model = pickle.load(file)\n",
    "            \n",
    "    # Test model \n",
    "    knn_predictions = knn_model.predict(test_data_w2v_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_kNN):\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    score_catagory_labels = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    matrix = confusion_matrix(test_labels, knn_predictions)\n",
    "    sns.heatmap(matrix.T, square = True, annot = True, fmt = \"d\", \n",
    "                xticklabels = score_catagory_labels, yticklabels = score_catagory_labels)\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute and print classification performance metrics\n",
    "    print(\"Accuracy:\\t%f\" % accuracy_score(test_labels, knn_predictions))\n",
    "    print(\"F1-score:\\t%f\" % f1_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"Precision:\\t%f\" % precision_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"Recall:\\t\\t%f\" % recall_score(test_labels, knn_predictions, average = \"macro\"))\n",
    "    print(\"\\nClassification performance:\\n%s\" % classification_report(test_labels, knn_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43ad334a0b661041421fbde0c35614c1",
     "grade": false,
     "grade_id": "cell-ceb568d7b9979383",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 4\n",
    "Implement a Convolutional Neural Network (CNN) model for predicting the rating of a food review. The model must have at least two convolutional layers. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**13%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc79d3616790883ed0539f3416cb92ad",
     "grade": true,
     "grade_id": "cell-8062f67e02d4c61f",
     "locked": false,
     "points": 13,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74843fe33a4f86a21469871aac52bb90",
     "grade": false,
     "grade_id": "cell-a985e9ca1140281d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 5\n",
    "Implement a Recurrent Neural Network (RNN) or a Long Short-Term Memory (LSTM) model for predicting the rating of a food review. The model must have at least two RNN/LSTM layers. Train your model on the training set and test it on the test set. Use an appropriate text representation. (**12%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb7179dcc099d3d51db8e0d4d4c53c7b",
     "grade": true,
     "grade_id": "cell-76f081948cba4b02",
     "locked": false,
     "points": 12,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5e477712b6bad9901556381dd829392",
     "grade": false,
     "grade_id": "cell-9f3d1c8c43462384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 6\n",
    "Compute the confusion matrix, accuracy, F1-score, precision and recall for each model. (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5080f7d517214809afe68eee9318b427",
     "grade": true,
     "grade_id": "cell-b3a9e53040d493c1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9def807c7734179b60c1d5121bbbd436",
     "grade": false,
     "grade_id": "cell-290a6e3bf464e305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation - Task 7\n",
    "Store the **four** trained models in files and implement a function `predict_food_review(text, model)` that given a <ins>text string</ins> (‚Äú`text`‚Äù) and model <ins>filename</ins> (‚Äú`model`‚Äù), it will load the pre-trained model, and predict the food review rating of the input text. The function should be able to work without requiring to rerun all or part of your code. (**10%**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03a2117734166d6e91043d88d5c5ef8a",
     "grade": true,
     "grade_id": "cell-f384d017d7d6ac75",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66fe20bf6b18e122ab5eb3a8110ee13b",
     "grade": false,
     "grade_id": "cell-3632d0c81d039058",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 1\n",
    "Critical discussion about the dataset (suitability, problems, class balance, etc.). (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c04a7d6b4dc1614cce18ae7dc9b59ee0",
     "grade": true,
     "grade_id": "cell-723b0c0e08ba0f30",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e16e80cbdb327b4bd8b3dc8644c93953",
     "grade": false,
     "grade_id": "cell-cf6f3bf73d0b219c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 2\n",
    "Description and justification of the data preparation step(s) used. (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d827d373523a1ebd5f7adf108d5fc5e",
     "grade": true,
     "grade_id": "cell-ff3a7a6577a764fb",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bfd5a727276dd53f136df6d1d262fe6",
     "grade": false,
     "grade_id": "cell-0a65e991a54b21c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 3\n",
    "Description and commentary on the machine learning architectures used, including a description and justification of the text representation method(s) used. (**7%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03960b9d6fae49a8bbd6547d5c67b9fc",
     "grade": true,
     "grade_id": "cell-6c64da91adfef770",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "874f5d8565ae3e5a4cb52d837e4beceb",
     "grade": false,
     "grade_id": "cell-7112118f421c6a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 4\n",
    "Detailed performance evaluation of the trained machine learning models in terms of the computed performance metrics. (**5%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "071a2e19285688d52725adc2063d2044",
     "grade": true,
     "grade_id": "cell-201e49e468eaa417",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac8dc11dd7f998b7d3d5c0e904c08c5f",
     "grade": false,
     "grade_id": "cell-5e6e5b8b57811a63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Report - Task 5\n",
    "Critical discussion on the achieved results, including potential limitations and usage instructions/suggestions. (**6%**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27dd1c5197d66c3081a133456110abb0",
     "grade": true,
     "grade_id": "cell-11c60b80d50f1d27",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
